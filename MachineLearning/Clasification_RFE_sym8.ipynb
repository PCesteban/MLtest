{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.naive_bayes import BernoulliNB\n",
    "from sklearn import tree\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "from numpy import percentile\n",
    "from sklearn.model_selection import cross_validate\n",
    "from sklearn.metrics import make_scorer\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from numpy import percentile\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.decomposition import PCA\n",
    "from sklearn.preprocessing import normalize\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn import datasets, metrics\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.feature_selection import SelectFromModel\n",
    "from sklearn.ensemble import ExtraTreesClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.feature_selection import RFE\n",
    "from sklearn.svm import SVR\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "from sklearn.svm import LinearSVC"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [],
   "source": [
    "df_final = pd.read_csv('waveletsym8_Prueba.csv')\n",
    "target = df_final['target']\n",
    "df_final = df_final.drop(df_final.columns[[0,373]], axis='columns')\n",
    "estimator = SVR(kernel=\"linear\")\n",
    "num=80\n",
    "numCV = 9\n",
    "\n",
    "#60\n",
    "\n",
    "X= df_final\n",
    "y= target\n",
    "\n",
    "rng = np.random.RandomState(0)\n",
    "sss = StratifiedShuffleSplit(n_splits=2, test_size=0.28, random_state=rng)\n",
    "\n",
    "for train_index, test_index in sss.split(X, y):\n",
    "    \n",
    "    X_train, X_test = X.loc[train_index,:], X.loc[test_index,:]\n",
    "    y_train, y_test = y.loc[train_index], y.loc[test_index]\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(527)\n",
    "\n",
    "pipelineKNN = make_pipeline(StandardScaler(),RFE(estimator, step=1, n_features_to_select=num),\n",
    "                         KNeighborsClassifier(n_neighbors=15))\n",
    "pipelineKNN.fit(X_train, y_train)\n",
    "predsKNN = pipelineKNN.predict(X_test)\n",
    "\n",
    "\n",
    "scoresKNN = cross_val_score(pipelineKNN, X_train, y_train, cv=numCV)\n",
    "quartilesKNN = percentile(scoresKNN, [25, 50, 75])\n",
    "avKNN = scoresKNN.mean()\n",
    "minKNN, maxKNN = scoresKNN.min(), scoresKNN.max()\n",
    "\n",
    "\n",
    "accKNN=accuracy_score(y_test, predsKNN)\n",
    "accKNN= accKNN*100\n",
    "tnKNN, fpKNN, fnKNN, tpKNN = confusion_matrix(y_test, predsKNN).ravel()\n",
    "SensKNN = (tpKNN/(tpKNN+fnKNN))*100\n",
    "SpeciKNN = (tnKNN/(tnKNN+fpKNN))*100\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(527)\n",
    "pipelineNB = make_pipeline(StandardScaler(),RFE(estimator, step=1,n_features_to_select=num),\n",
    "                         BernoulliNB(alpha = 0.1, binarize = 0.45))\n",
    "pipelineNB.fit(X_train, y_train)\n",
    "predsNB = pipelineNB.predict(X_test)\n",
    "\n",
    "\n",
    "modelNB = BernoulliNB(alpha = 0.1, binarize = 0.45)\n",
    "scoresNB = cross_val_score(pipelineNB, X_train, y_train, cv=numCV)\n",
    "quartilesNB = percentile(scoresNB, [25, 50, 75])\n",
    "avNB = scoresNB.mean()\n",
    "minNB, maxNB = scoresNB.min(), scoresNB.max()\n",
    "\n",
    "\n",
    "accNB=accuracy_score(y_test, predsNB)\n",
    "accNB= accNB*100\n",
    "tnNB, fpNB, fnNB, tpNB = confusion_matrix(y_test, predsNB).ravel()\n",
    "SensNB = (tpNB/(tpNB+fnNB))*100\n",
    "SpeciNB = (tnNB/(tnNB+fpNB))*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(527)\n",
    "pipelineADA = make_pipeline(StandardScaler(), RFE(estimator, step=1,n_features_to_select=num),\n",
    "                         AdaBoostClassifier(n_estimators=150, random_state=rng))\n",
    "pipelineADA.fit(X_train, y_train)\n",
    "predsADA = pipelineADA.predict(X_test)\n",
    "\n",
    "\n",
    "scoresADA= cross_val_score(pipelineADA, X_train, y_train,cv=numCV)\n",
    "quartilesADA = percentile(scoresADA, [25, 50, 75])\n",
    "avADA = scoresADA.mean()\n",
    "minADA, maxADA = scoresADA.min(), scoresADA.max()\n",
    "\n",
    "\n",
    "accADA=accuracy_score(y_test, predsADA)\n",
    "accADA= accADA*100\n",
    "tnADA, fpADA, fnADA, tpADA = confusion_matrix(y_test, predsADA).ravel()\n",
    "SensADA = (tpADA/(tpADA+fnADA))*100\n",
    "SpeciADA = (tnADA/(tnADA+fpADA))*100\n",
    "\n",
    "#confusion_matrix = pd.crosstab(y_test, predsADA, rownames=['Actual'], colnames=['Predicted'])\n",
    "#print (confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(527)\n",
    "pipelineRF = make_pipeline(StandardScaler(),RFE(estimator, step=1,n_features_to_select=num),\n",
    "                         RandomForestClassifier(n_estimators=150, random_state=rng))\n",
    "pipelineRF.fit(X_train, y_train)\n",
    "predsRF = pipelineRF.predict(X_test)\n",
    "\n",
    "\n",
    "scoresRF = cross_val_score(pipelineRF, X_train, y_train, cv=numCV)\n",
    "quartilesRF = percentile(scoresRF, [25, 50, 75])\n",
    "avRF = scoresRF.mean()\n",
    "minRF, maxRF = scoresRF.min(), scoresRF.max()\n",
    "\n",
    "accRF=accuracy_score(y_test, predsRF)\n",
    "accRF= accRF*100\n",
    "tnRF, fpRF, fnRF, tpRF = confusion_matrix(y_test, predsRF).ravel()\n",
    "\n",
    "\n",
    "#confusion_matrix = pd.crosstab(y_test, predsRF, rownames=['Actual'], colnames=['Predicted'])\n",
    "#print (confusion_matrix)\n",
    "SensRF = (tpRF/(tpRF+fnRF))*100\n",
    "SpeciRF = (tnRF/(tnRF+fpRF))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(527)\n",
    "pipelineGBC = make_pipeline(StandardScaler(),RFE(estimator, step=1,n_features_to_select=num),\n",
    "                         GradientBoostingClassifier(random_state=rng, n_estimators=100))\n",
    "pipelineGBC.fit(X_train, y_train)\n",
    "predsGBC = pipelineGBC.predict(X_test)\n",
    "\n",
    "\n",
    "scoresGBC = cross_val_score(pipelineGBC, X_train, y_train, cv=numCV)\n",
    "quartilesGBC = percentile(scoresGBC, [25, 50, 75])\n",
    "avGBC = scoresGBC.mean()\n",
    "minGBC, maxGBC = scoresGBC.min(), scoresGBC.max()\n",
    "\n",
    "\n",
    "accGBC=accuracy_score(y_test, predsGBC)\n",
    "accGBC= accGBC*100\n",
    "tnGBC, fpGBC, fnGBC, tpGBC = confusion_matrix(y_test, predsGBC).ravel()\n",
    "SensGBC = (tpGBC/(tpGBC+fnGBC))*100\n",
    "SpeciGBC = (tnGBC/(tnGBC+fpGBC))*100\n",
    "\n",
    "#confusion_matrix = pd.crosstab(y_test, predsGBC, rownames=['Actual'], colnames=['Predicted'])\n",
    "#print (confusion_matrix)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(527)\n",
    "pipelineSVM = make_pipeline(StandardScaler(),RFE(estimator, step=1,n_features_to_select=num),\n",
    "                        LinearSVC(random_state=rng))\n",
    "pipelineSVM.fit(X_train, y_train)\n",
    "predsSVM = pipelineSVM.predict(X_test)\n",
    "\n",
    "scoresSVM = cross_val_score(pipelineSVM, X_train, y_train, cv=numCV)\n",
    "quartilesSVM = percentile(scoresSVM, [25, 50, 75])\n",
    "avSVM = scoresSVM.mean()\n",
    "minSVM, maxSVM = scoresSVM.min(), scoresSVM.max()\n",
    "\n",
    "\n",
    "accSVM=accuracy_score(y_test, predsSVM)\n",
    "accSVM= accSVM*100\n",
    "tnSVM, fpSVM, fnSVM, tpSVM = confusion_matrix(y_test, predsSVM).ravel()\n",
    "SensSVM = (tpSVM/(tpSVM+fnSVM))*100\n",
    "SpeciSVM = (tnSVM/(tnSVM+fpSVM))*100"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(527)\n",
    "pipelineGLMNET = make_pipeline(StandardScaler(),RFE(estimator, step=1,n_features_to_select=num),\n",
    "                        LogisticRegression(random_state=0))\n",
    "pipelineGLMNET.fit(X_train, y_train)\n",
    "predsGLMNET = pipelineGLMNET.predict(X_test)\n",
    "\n",
    "scoresGLMNET = cross_val_score(pipelineGLMNET, X_train, y_train, cv=numCV)\n",
    "quartilesGLMNET = percentile(scoresGLMNET, [25, 50, 75])\n",
    "avGLMNET = scoresGLMNET.mean()\n",
    "minGLMNET, maxGLMNET = scoresGLMNET.min(), scoresGLMNET.max()\n",
    "\n",
    "\n",
    "accGLMNET=accuracy_score(y_test, predsGLMNET)\n",
    "accGLMNET= accGLMNET*100\n",
    "tnGLMNET, fpGLMNET, fnGLMNET, tpGLMNET = confusion_matrix(y_test, predsGLMNET).ravel()\n",
    "SensGLMNET = (tpGLMNET/(tpGLMNET+fnGLMNET))*100\n",
    "SpeciGLMNET = (tnGLMNET/(tnGLMNET+fpGLMNET))*100\n",
    "\n",
    "#confusion_matrix = pd.crosstab(y_test, predsGLMNET, rownames=['Actual'], colnames=['Predicted'])\n",
    "#print (confusion_matrix)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Model</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Sensitivity</th>\n",
       "      <th>Specificity</th>\n",
       "      <th>Accuracy_CV</th>\n",
       "      <th>Min</th>\n",
       "      <th>Max</th>\n",
       "      <th>q1</th>\n",
       "      <th>q2</th>\n",
       "      <th>q3</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>KNN</td>\n",
       "      <td>63.636364</td>\n",
       "      <td>45.454545</td>\n",
       "      <td>81.818182</td>\n",
       "      <td>0.555556</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>NB</td>\n",
       "      <td>77.272727</td>\n",
       "      <td>72.727273</td>\n",
       "      <td>81.818182</td>\n",
       "      <td>0.537037</td>\n",
       "      <td>0.166667</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>ADA</td>\n",
       "      <td>68.181818</td>\n",
       "      <td>54.545455</td>\n",
       "      <td>81.818182</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>RF</td>\n",
       "      <td>86.363636</td>\n",
       "      <td>72.727273</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.685185</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>GBC</td>\n",
       "      <td>72.727273</td>\n",
       "      <td>54.545455</td>\n",
       "      <td>90.909091</td>\n",
       "      <td>0.574074</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.833333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.833333</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>SVM</td>\n",
       "      <td>77.272727</td>\n",
       "      <td>54.545455</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.666667</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>LogisticR</td>\n",
       "      <td>81.818182</td>\n",
       "      <td>63.636364</td>\n",
       "      <td>100.000000</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.000000</td>\n",
       "      <td>1.000000</td>\n",
       "      <td>0.333333</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.666667</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "       Model   Accuracy  Sensitivity  Specificity  Accuracy_CV       Min  \\\n",
       "0        KNN  63.636364    45.454545    81.818182     0.555556  0.166667   \n",
       "1         NB  77.272727    72.727273    81.818182     0.537037  0.166667   \n",
       "2        ADA  68.181818    54.545455    81.818182     0.685185  0.500000   \n",
       "3         RF  86.363636    72.727273   100.000000     0.685185  0.333333   \n",
       "4        GBC  72.727273    54.545455    90.909091     0.574074  0.333333   \n",
       "5        SVM  77.272727    54.545455   100.000000     0.500000  0.000000   \n",
       "6  LogisticR  81.818182    63.636364   100.000000     0.500000  0.000000   \n",
       "\n",
       "        Max        q1        q2        q3  \n",
       "0  0.833333  0.500000  0.500000  0.666667  \n",
       "1  0.833333  0.500000  0.500000  0.666667  \n",
       "2  0.833333  0.666667  0.666667  0.833333  \n",
       "3  1.000000  0.500000  0.833333  0.833333  \n",
       "4  0.833333  0.500000  0.500000  0.833333  \n",
       "5  1.000000  0.333333  0.666667  0.666667  \n",
       "6  1.000000  0.333333  0.500000  0.666667  "
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Results = {'Model': ['KNN', \n",
    "                 'NB', \n",
    "                 'ADA',\n",
    "                'RF', 'GBC', 'SVM','LogisticR'],\n",
    "         'Accuracy': [accKNN,accNB, accADA, accRF, accGBC, accSVM, accGLMNET], \n",
    "         'Sensitivity':[SensKNN,SensNB, SensADA, SensRF, SensGBC, SensSVM, SensGLMNET],\n",
    "        'Specificity':[SpeciKNN,SpeciNB, SpeciADA, SpeciRF, SpeciGBC, SpeciSVM, SpeciGLMNET],\n",
    "          'Accuracy_CV': [avKNN,avNB, avADA, avRF, avGBC, avSVM, avGLMNET], \n",
    "         'Min':[minKNN,minNB, minADA, minRF, minGBC, minSVM, minGLMNET],\n",
    "        'Max':[maxKNN,maxNB, maxADA, maxRF, maxGBC, maxSVM, maxGLMNET],\n",
    "        'q1':[quartilesKNN[0],quartilesNB[0],quartilesADA[0],quartilesRF[0],quartilesGBC[0],quartilesSVM[0],quartilesGLMNET[0]],\n",
    "          'q2':[quartilesKNN[1],quartilesNB[1],quartilesADA[1],quartilesRF[1],quartilesGBC[1],quartilesSVM[1],quartilesGLMNET[1]],\n",
    "          'q3':[quartilesKNN[2],quartilesNB[2],quartilesADA[2],quartilesRF[2],quartilesGBC[2],quartilesSVM[2],quartilesGLMNET[2]]\n",
    "          }\n",
    "\n",
    "df_results = pd.DataFrame(Results)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "17    0\n",
       "14    1\n",
       "58    1\n",
       "7     0\n",
       "64    1\n",
       "12    1\n",
       "30    1\n",
       "49    0\n",
       "61    0\n",
       "27    0\n",
       "73    0\n",
       "26    1\n",
       "69    0\n",
       "48    1\n",
       "38    1\n",
       "75    0\n",
       "33    0\n",
       "42    1\n",
       "66    1\n",
       "5     0\n",
       "23    0\n",
       "62    1\n",
       "Name: target, dtype: int64"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
